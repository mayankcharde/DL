{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faee2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe90d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"qoute_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55251bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               quote           Author\n",
       "0  “The world as we have created it is a process ...  Albert Einstein\n",
       "1  “It is our choices, Harry, that show what we t...     J.K. Rowling\n",
       "2  “There are only two ways to live your life. On...  Albert Einstein\n",
       "3  “The person, be it gentleman or lady, who has ...      Jane Austen\n",
       "4  “Imperfection is beauty, madness is genius and...   Marilyn Monroe"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f540d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3038, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45509c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    “The world as we have created it is a process ...\n",
       "1    “It is our choices, Harry, that show what we t...\n",
       "2    “There are only two ways to live your life. On...\n",
       "3    “The person, be it gentleman or lady, who has ...\n",
       "4    “Imperfection is beauty, madness is genius and...\n",
       "Name: quote, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "quotes = df['quote']\n",
    "quotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94abf0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTINGALLQUOTES TO LOWERCASE\n",
    "quotes=quotes.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aedbd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# HERE WE REMOVE ALL PUNCTUATIONS LIKE COMMAS ETC FROM QUOTES\n",
    "translator= str.maketrans('','',string.punctuation) \n",
    "quotes= quotes.apply(lambda x: x.translate(translator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6a83fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    “the world as we have created it is a process ...\n",
       "1    “it is our choices harry that show what we tru...\n",
       "2    “there are only two ways to live your life one...\n",
       "3    “the person be it gentleman or lady who has no...\n",
       "4    “imperfection is beauty madness is genius and ...\n",
       "Name: quote, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f759f97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74bfd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "#  OOV TOKEN HANDLES UNKNOWN WORDS \n",
    "tokenizer  = Tokenizer(num_words=vocab_size)\n",
    "# LEARNS A WORD DICTIONARY FROM ALL SENTENCES\n",
    "tokenizer.fit_on_texts(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b69e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 1),\n",
       " ('you', 2),\n",
       " ('to', 3),\n",
       " ('and', 4),\n",
       " ('a', 5),\n",
       " ('i', 6),\n",
       " ('is', 7),\n",
       " ('of', 8),\n",
       " ('that', 9),\n",
       " ('it', 10)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERTING RANDOM WORDS INTO WORDS INDEX THAT WILL SHOWS IN FORM OF INDEX\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "# WE ARE HERE PRINTING IN LIST FORM UP TO INDEX 10\n",
    "list(word_index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a690d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT CONVERTS SEQUENCE INTO NUMBERS SEQUENCES\n",
    "# \"I love this product\" → [12, 45, 6, 98] \n",
    "sequences = tokenizer.texts_to_sequences(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b4b8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“the world as we have created it is a process of our thinking it cannot be changed without changing our thinking”\n",
      "“it is our choices harry that show what we truly are far more than our abilities”\n",
      "“there are only two ways to live your life one is as though nothing is a miracle the other is as though everything is a miracle”\n"
     ]
    }
   ],
   "source": [
    "# HERE WE PRINT FIRST 3 QUOTES IN FORM OF SEQUENCES\n",
    "for i in range(3):\n",
    "    print(quotes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa375ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[713, 62, 29, 19, 16, 946, 10, 7, 5, 1156, 8, 70, 293, 10, 145, 12, 809, 104, 752, 70, 2461]\n",
      "[947, 7, 70, 871, 373, 9, 433, 21, 19, 465, 14, 294, 52, 54, 70, 3676]\n",
      "[1337, 14, 53, 201, 714, 3, 81, 15, 36, 37, 7, 29, 329, 93, 7, 5, 1157, 1, 101, 7, 29, 329, 126, 7, 5, 3677]\n"
     ]
    }
   ],
   "source": [
    "# HERE WE PRINT FIRST 3 QUOTES IN FORM OF SEQUENCES(NUMBERS)\n",
    "for i in range(3):\n",
    "    print(sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "772fabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= []\n",
    "y= []\n",
    "# X contains partial sequences\n",
    "\n",
    "# y contains the next token to predict\n",
    "\n",
    "for seq in sequences:\n",
    "    # RANGE 1 SE START HORI HAI AUR LEN TAK JAYEGA\n",
    "  for i in range(1,len(seq)):\n",
    "    # INPUT ME SABSE PAHELE SE SARE AYEGE SEQUENCE \n",
    "    input_seq = seq[:i]\n",
    "    # OUTPUT ME LAST JO SEQUENCE HOGA YA JO LAST WORD YA NUMBER HOGA WO AYEGA \n",
    "    output_seq = seq[i]\n",
    "    #  HERE WE ARE APPENDING \n",
    "    X.append(input_seq)\n",
    "    y.append(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f33dd4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85271"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e412fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85271"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "629cf081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745\n"
     ]
    }
   ],
   "source": [
    "# FINDS LENGTH OF LONGEST SENTENCE \n",
    "# BASICALLY IT FINDS MAXM LENGTH THAT HOW MUCH LEN OF NUMBERS IS FORMING FROM WORDS TO NUMBERS SEQUENCE \n",
    "max_len = max(len(x) for x in X)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb62d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# HERE WE ARE MAKING SAME LENGTH BY ADDING 0 AT THE BEGGINING(PRE) OF SEQUENCES\n",
    "X_padded = pad_sequences(X, maxlen=max_len, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aa3f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46f7264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85271, 745)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96d83d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  HERE WE ARE DOING ONE HOT ENCODEING FOR CATEGORICAL OUTPUT\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_one_hot = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "934775fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85271,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c52ee489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85271, 10000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\tConvert word IDs → dense vectors\n",
    "# SimpleRNN\tCore RNN layer\n",
    "# Dense\tFinal output layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4519373",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "rnn_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf81d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#  HERE WE ARE MAKING A SEQUENTIAL MODEL\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "\n",
    "# 1. Embedding Layer: Converts word indices into dense vectors of a fixed size.\n",
    "rnn_model.add(\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)\n",
    ")\n",
    "# 2. SimpleRNN Layer: Processes the sequence data.BASICALLY HERE WE USED SIMPLE RNN\n",
    "rnn_model.add(SimpleRNN(units=rnn_units))\n",
    "#  OUTPUT LAYER\n",
    "# A Dense layer with softmax activation to predict the next word in the vocabulary.\n",
    "rnn_model.add(Dense(units=vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69bcfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7cdede0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14bbb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# NOW HERE WE ARE PERFORMING WITH LSTM MODEL\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)\n",
    ")\n",
    "lstm_model.add(LSTM(units=rnn_units))\n",
    "lstm_model.add(Dense(units=vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67ce24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bfb86e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "lstm_model.summary()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#  HERE WE LOAD OUR MODEL \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lstm_model = load_model(\"lstm_model (1).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e913887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_model.save(\"lstm_model.h5\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {}\n",
    "#  HERE WE ADD A LOOP IN WHICH WE ACCEPTING WORD AND INDEX AND KEEPING AT WHAT INDEX WHICH WORD IS THERE\n",
    "# AND ADD IT INTO THE INDEX_TO_WORD DICTIONARY\n",
    "for word, index in word_index.items():\n",
    "    index_to_word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MAKE ALL SENTENCE INTO THE SAME LENGTH\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HERE WE MAKE A FUNCTION FOR WORD PREDICTOR \n",
    "# WHICH ACCEPTS MODEL LIKE SIMPLERNN, LSTM ETC...\n",
    "# TOKENZER , TEXT AND MAX_LENGTH\n",
    "def predictor(model,tokenizer,text,max_len):\n",
    "  #  CONVERTS TEXT INTO LOWER CASE \n",
    "  text = text.lower()\n",
    "# CONVERT TEXT INTO TOKENIZE[TOKENS] FROM 0TH POSITION\n",
    "  seq = tokenizer.texts_to_sequences([text])[0]\n",
    "  # PAD_SEQUENCE MEANS ADD 0 IN EMPTY POSITION...HERE PADDING IS PRE SO 0 IS ADD ON STARTING EMPTY SPACES \n",
    "  seq = pad_sequences([seq], maxlen=max_len, padding='pre')\n",
    "\n",
    "# PREDICTION\n",
    "  pred = model.predict(seq,verbose = 0)\n",
    "  #  CONVERT FOR NUMERICAL OPERATION FORM \n",
    "  pred_index = np.argmax(pred)\n",
    "  # STORE IN THE DICTIONARY\n",
    "  return index_to_word[pred_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a2372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worrying\n"
     ]
    }
   ],
   "source": [
    "# PASSING SENTENCE TO PREDICT NEXT WORD\n",
    "seed_text = \"what are you\"\n",
    "# GIVING ALL PARAMS TO FUNCTION\n",
    "next_word = predictor(lstm_model,tokenizer,seed_text,max_len)\n",
    "print(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c776bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TEXT GENERATOR FUNCTION \n",
    "# HERE WE HAVE ONE EXTRA THING WHICH IS N_WORDS FOR OUR TEXT GENERATION\n",
    "def generate_text(model,tokenizer,seed_text,max_len,n_words):\n",
    "  for _ in range(n_words):\n",
    "    next_word = predictor(model,tokenizer,seed_text,max_len)\n",
    "    # AGAR NEXT_WORD EMPTY HAI TO BREAK KRDO\n",
    "    if next_word == \"\":\n",
    "      break\n",
    "    # NHI TO SEED_TEXT ME ADD KR DO\n",
    "    seed_text += \" \" + next_word\n",
    "  return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa5feef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you a  thousand times i wrote the less if it does not\n"
     ]
    }
   ],
   "source": [
    "seed = \"are you a \"\n",
    "generate_text = generate_text(lstm_model,tokenizer,seed,max_len,10)\n",
    "print(generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING PICKLE FILE OF TOKENIZER\n",
    "import pickle\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "  pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a046353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING PICKLE FILE OF MAX_LEN\n",
    "with open(\"max_len.pkl\", \"wb\") as f:\n",
    "  pickle.dump(max_len, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3afa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359e27b8",
   "metadata": {},
   "source": [
    "Library\tPurpose\n",
    "numpy\tNumerical operations\n",
    "tensorflow / keras\tBuild deep learning model\n",
    "Tokenizer\tConvert words â†’ numbers\n",
    "pad_sequences\tMake all sentences same length\n",
    "Embedding\tConvert word IDs â†’ dense vectors\n",
    "SimpleRNN\tCore RNN layer\n",
    "Dense\tFinal output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578f711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4431aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sentences = [\n",
    " \"I love this product\",\n",
    " \"This movie made me smile\",\n",
    " \"Service was friendly and quick\",\n",
    " \"Today felt bright and happy\",\n",
    " \"This is the best day\",\n",
    " \"Absolutely fantastic experience\",\n",
    " \"I enjoyed every single moment\",\n",
    " \"Great job, well done\",\n",
    " \"The food tasted delicious\",\n",
    " \"Totally recommend to everyone\",\n",
    " \"Very satisfied with results\",\n",
    " \"This worked better than expected\",\n",
    " \"Amazing quality and value\",\n",
    " \"Such a pleasant surprise\",\n",
    " \"I feel positive about this\",\n",
    " \"I hate this product\",\n",
    " \"This movie bored me\",\n",
    " \"Service was rude and slow\",\n",
    " \"Today was cold and lonely\",\n",
    " \"This is the worst day\",\n",
    " \"Terrible experience overall\",\n",
    " \"I regret buying this\",\n",
    " \"Very disappointed with results\",\n",
    " \"The food tasted awful\",\n",
    " \"Do not recommend this\",\n",
    " \"It broke after one use\",\n",
    " \"Not worth the money\",\n",
    " \"Utterly frustrating and annoying\",\n",
    " \"I feel negative about this\",\n",
    " \"Such a waste of time\",\n",
    "]\n",
    "\n",
    "labels= [1]*15 + [0]*15  # 1 for positive, 0 for negative  \n",
    "#  THIS IS CREATED BECAUSE NEURAL NETWORKS WORK EFFIECIENTLY WITH NUMPY ARRAYS NOT PYTHON LISTS \n",
    "labels = np.array(labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c258fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of unique words the model will remember.\n",
    "vocab_size = 2000\n",
    "# IT CONVERTS WORDS INTO NUMBERS \n",
    "#  OOV TOKEN HANDLES UNKNOWN WORDS \n",
    "tok = Tokenizer(num_words=vocab_size,oov_token=\"\")\n",
    "# LEARNS A WORD DICTIONARY FROM ALL SENTENCES \n",
    "tok.fit_on_texts(sentences)\n",
    "# IT CONVERTS SEQUENCE INTO NUMBERS SEQUENCES\n",
    "# \"I love this product\" â†’ [12, 45, 6, 98] \n",
    "seqs = tok.texts_to_sequences(sentences)\n",
    "# FINDS LENGTH OF LONGEST SENTENCE \n",
    "# BASICALLY IT FINDS MAXM LENGTH THAT HOW MUCH LEN OF NUMBERS IS FORMING FROM WORDS TO NUMBERS SEQUENCE \n",
    "maxlen = max(len(s) for s in seqs)\n",
    "# HERE WE ARE MAKING SAME LENGTH BY ADDING 0 AT THE END\n",
    "X = pad_sequences(seqs,maxlen= maxlen, padding='post')\n",
    "#  THIS IS CREATED BECAUSE NEURAL NETWORKS WORK EFFIECIENTLY WITH NUMPY ARRAYS NOT PYTHON LISTS \n",
    "y = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b9aff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 26,  2,  7,  0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS IS THE NUMERICAL REPRESENTATION OF \"I love this product\" I.E FIRST SENTENCE\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b488ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EACH WORD HAS 16 DIM VECTOR\n",
    "embed_dim = 16\n",
    "# RNN HAS 8 MEMORY UNITS(NEURON)\n",
    "rnn_units = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b14e906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,000</span> â”‚ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ not_equal_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ simple_rnn          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> â”‚ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         â”‚                   â”‚            â”‚ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> â”‚ simple_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input (\u001b[38;5;33mInputLayer\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embed (\u001b[38;5;33mEmbedding\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     â”‚     \u001b[38;5;34m32,000\u001b[0m â”‚ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ not_equal_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mNotEqual\u001b[0m)          â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ simple_rnn          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚        \u001b[38;5;34m200\u001b[0m â”‚ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      â”‚\n",
       "â”‚ (\u001b[38;5;33mSimpleRNN\u001b[0m)         â”‚                   â”‚            â”‚ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ out (\u001b[38;5;33mDense\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m9\u001b[0m â”‚ simple_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,209</span> (125.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,209\u001b[0m (125.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,209</span> (125.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,209\u001b[0m (125.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  THIS IS INPUT LAYER IT RECIVES SEQUENCE OF WORDS NUMBERS AS INPUT\n",
    "# LENGTH IS MAX LENGTH , DATA TYPE IS INT32\n",
    "inp = Input(shape=(maxlen,), dtype='int32', name='input')\n",
    "# IT CONVERTS WORD ID'S INTO MEANINGFUL VECTORS OF DIMENSION 16 \n",
    "# MASK_ZERO=TRUE MEANS IGNORE ZERO PADDING IN SEQUENCE\n",
    "x=Embedding(input_dim=vocab_size, output_dim = embed_dim, mask_zero=True, name='embed')(inp)\n",
    "# SIMPLE RNN LAYER WITH 8 UNITS\n",
    "# Reads words one by one\n",
    "\n",
    "# Keeps memory of previous words\n",
    "\n",
    "# Outputs only the final memory state\n",
    "rnn= SimpleRNN(units=rnn_units, return_sequences=False, return_state=False, name='simple_rnn')\n",
    "# Feeds embedded text into RNN\n",
    "x_last = rnn(x)\n",
    "# Converts RNN output â†’ probability\n",
    "\n",
    "# sigmoid â†’ value between 0 and 1\n",
    "\n",
    "# 1 = Positive, 0 = Negative\n",
    "out=  Dense(1, activation='sigmoid', name='out')(x_last)\n",
    "# Connects input â†’ output\n",
    "\n",
    "# Creates the final model\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "# Adam â†’ fast optimizer\n",
    "\n",
    "# Binary crossentropy â†’ yes/no classification\n",
    "\n",
    "# Accuracy â†’ performance metric\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Displays model layers, shapes & parameters\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cc5f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5000 - loss: 0.6926\n",
      "Epoch 2/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6667 - loss: 0.6769 \n",
      "Epoch 3/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7667 - loss: 0.6629\n",
      "Epoch 4/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8667 - loss: 0.6489\n",
      "Epoch 5/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6350 \n",
      "Epoch 6/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6195 \n",
      "Epoch 7/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9333 - loss: 0.6038 \n",
      "Epoch 8/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.5872 \n",
      "Epoch 9/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.5700 \n",
      "Epoch 10/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.5511 \n",
      "Epoch 11/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.5308 \n",
      "Epoch 12/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.5101 \n",
      "Epoch 13/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.4883 \n",
      "Epoch 14/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.4650 \n",
      "Epoch 15/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.4425 \n",
      "Epoch 16/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.4184 \n",
      "Epoch 17/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3947 \n",
      "Epoch 18/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.3712 \n",
      "Epoch 19/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.3474 \n",
      "Epoch 20/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.3253 \n",
      "Epoch 21/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.3030 \n",
      "Epoch 22/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2821 \n",
      "Epoch 23/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2623 \n",
      "Epoch 24/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2440 \n",
      "Epoch 25/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2263 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cf3fa6b4a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model.fit() trains the RNN by adjusting its weights over multiple epochs using batches of input data.\n",
    "model.fit(X,y,epochs= 25,batch_size = 8,verbose = 1)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdae8fa",
   "metadata": {},
   "source": [
    "Task\n",
    "Create an intermediate Keras model to visualize the outputs of the embedding layer and the hidden states of the SimpleRNN layer from the existing model. Then, use this intermediate model to predict on the input data and visualize the outputs.\n",
    "\n",
    "Create intermediate model\n",
    "Subtask:\n",
    "Build a new Keras Model that takes the same input as the original model but outputs the embedding layer and the hidden states of the SimpleRNN layer.\n",
    "\n",
    "Reasoning: Define an intermediate Keras model with the same input as the original model and outputs from the embedding and simple RNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32041712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intermediate_model = Model(inputs=model.inputs, outputs=[model.get_layer('embed').output, model.get_layer('simple_rnn').output])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd8e8f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied RNN weights into sequence-inspection RNN.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step\n",
      "Sentence: I love this product\n",
      "Token ids: [[ 3 26  2  7  0]]\n",
      "Hidden states per timestep shape: (1, 5, 8)\n",
      "Hidden states (timesteps x units):\n",
      "[[ 0.038  0.01  -0.039 -0.001  0.003 -0.034  0.018  0.06 ]\n",
      " [ 0.262 -0.133  0.033  0.006  0.139 -0.098 -0.142  0.074]\n",
      " [-0.03  -0.112  0.292  0.284 -0.183  0.139  0.117  0.042]\n",
      " [ 0.115  0.014  0.073 -0.126  0.249 -0.396 -0.417  0.186]\n",
      " [ 0.115  0.014  0.073 -0.126  0.249 -0.396 -0.417  0.186]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import SimpleRNN as SRNN\n",
    "seq_inp = Input(shape=(maxlen,), dtype='int32')\n",
    "seq_emb = model.get_layer('embed')(seq_inp)  # reuse trained embedding\n",
    "\n",
    "# Create RNN with return_sequences=True\n",
    "rnn_seq = SRNN(units=rnn_units, return_sequences=True, name='rnn_seq')\n",
    "\n",
    "# DO NOT CALL build() manually\n",
    "seq_hidden = rnn_seq(seq_emb)  # builds automatically\n",
    "\n",
    "# Copy trained RNN weights\n",
    "try:\n",
    "    trained_weights = model.get_layer('simple_rnn').get_weights()\n",
    "    rnn_seq.set_weights(trained_weights)\n",
    "    print(\"Copied RNN weights into sequence-inspection RNN.\")\n",
    "except Exception as e:\n",
    "    print(\"Could not copy weights automatically:\", e)\n",
    "\n",
    "inspect_model = Model(inputs=seq_inp, outputs=seq_hidden)\n",
    "\n",
    "# Inspect\n",
    "idx = 0\n",
    "example_seq = X[idx:idx+1]  # shape (1, maxlen)\n",
    "hidden_seq = inspect_model.predict(example_seq)\n",
    "\n",
    "print(\"Sentence:\", sentences[idx])\n",
    "print(\"Token ids:\", example_seq)\n",
    "print(\"Hidden states per timestep shape:\", hidden_seq.shape)\n",
    "print(\"Hidden states (timesteps x units):\")\n",
    "print(np.round(hidden_seq[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d04a1",
   "metadata": {},
   "source": [
    "Built an inspection model that reveals the hidden state of the trained RNN at each word in the sentence.\n",
    "\n",
    "IN THIS CODE WE BASCIALLY BUILT AN INSPECTION MODEL THAT REVEALS THE HIDDEN STATE OF THE TRAINED RNN AT EACH WORD IN THE SENTENCE.\n",
    "\n",
    "PICK FIRST SENTENCE AND PREDICT HIDDEN STATES SUCH AS TOKEN ID AND HIDDEN STATES\n",
    "\n",
    "\n",
    "Dimension\tMeaning\n",
    "1\tOne sentence\n",
    "5\t5 time-steps (5 tokens)\n",
    "8\t8 RNN memory units\n",
    "\n",
    "Token ids: [[ 3 26  2  7  0]]\n",
    "IN TOKEN IDS 0 MEANS WE ADDED PADDING\n",
    "\n",
    "\n",
    "ğŸ”¹ Hidden states printed\n",
    "[[-0.016 -0.011 -0.013  0.053  0.073 -0.071  0.018 -0.019]   â† after \"I\"\n",
    " [ 0.045 -0.046 -0.210 -0.094 -0.181 -0.020 -0.137  0.099]   â† after \"love\"\n",
    " [-0.010 -0.243 -0.152 -0.143  0.133  0.031  0.351 -0.113]   â† after \"this\"\n",
    " [-0.336 -0.099 -0.260  0.179 -0.012 -0.316 -0.127 -0.114]   â† after \"product\"\n",
    " [-0.336 -0.099 -0.260  0.179 -0.012 -0.316 -0.127 -0.114]   â† padding (0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
